{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (dialogs-sgr)",
      "language": "python",
      "name": "dialogs-sgr"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "cells": [
    {
      "id": "md-000",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SGR Quality: Executive Notebook (C-Level)\n",
        "\n",
        "Цель: на одном экране показать **сильные кейсы**, **негативные кейсы** и **почему это важно бизнесу**.\n",
        "\n",
        "- Позитивные кейсы: `final_score_for_message >= 0.90` и `judge_label = 1`.\n",
        "- Негативные кейсы: строго **только последний успешный run** (`latest_run`, `judge_label = 0`).\n",
        "- Бизнес-вид: понятные русские поля без перегруза ID.\n"
      ]
    },
    {
      "id": "code-001",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 240)\n",
        "\n",
        "\n",
        "def resolve_db_path() -> Path:\n",
        "    cwd = Path.cwd().resolve()\n",
        "    candidates = [cwd / \"dialogs.db\", cwd.parent / \"dialogs.db\"]\n",
        "    candidates.extend(parent / \"dialogs.db\" for parent in cwd.parents)\n",
        "\n",
        "    for path in candidates:\n",
        "        if path.exists():\n",
        "            return path\n",
        "\n",
        "    raise FileNotFoundError(\"dialogs.db not found. Run: make init-fresh && make scan\")\n",
        "\n",
        "\n",
        "DB_PATH = resolve_db_path()\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "conn.row_factory = sqlite3.Row\n",
        "\n",
        "\n",
        "def qdf(sql: str, params: tuple[object, ...] = ()) -> pd.DataFrame:\n",
        "    return pd.read_sql_query(sql, conn, params=params)\n",
        "\n",
        "\n",
        "def latest_run_id() -> str:\n",
        "    row = conn.execute(\n",
        "        \"\"\"\n",
        "        SELECT run_id\n",
        "        FROM scan_runs\n",
        "        WHERE status = 'success'\n",
        "        ORDER BY started_at_utc DESC\n",
        "        LIMIT 1\n",
        "        \"\"\"\n",
        "    ).fetchone()\n",
        "    if row is None:\n",
        "        raise ValueError(\"No successful scan run found. Run: make scan\")\n",
        "    return str(row[\"run_id\"])\n",
        "\n",
        "\n",
        "def as_yes_no(value: object) -> str:\n",
        "    if pd.isna(value):\n",
        "        return \"N/A\"\n",
        "    return \"Да\" if bool(int(value)) else \"Нет\"\n",
        "\n",
        "\n",
        "def as_pct(value: object) -> str:\n",
        "    if pd.isna(value):\n",
        "        return \"N/A\"\n",
        "    return f\"{float(value):.1%}\"\n",
        "\n",
        "\n",
        "def style_business_table(df: pd.DataFrame, caption: str | None = None):\n",
        "    if df.empty:\n",
        "        print(\"Таблица пустая для выбранного условия.\")\n",
        "        return\n",
        "\n",
        "    styler = (\n",
        "        df.style.hide(axis=\"index\")\n",
        "        .set_properties(\n",
        "            **{\n",
        "                \"white-space\": \"pre-wrap\",\n",
        "                \"overflow-wrap\": \"anywhere\",\n",
        "                \"word-break\": \"break-word\",\n",
        "                \"vertical-align\": \"top\",\n",
        "                \"text-align\": \"left\",\n",
        "            }\n",
        "        )\n",
        "        .set_table_styles(\n",
        "            [\n",
        "                {\n",
        "                    \"selector\": \"th\",\n",
        "                    \"props\": [\n",
        "                        (\"text-align\", \"left\"),\n",
        "                        (\"white-space\", \"normal\"),\n",
        "                        (\"background-color\", \"#f4f6f8\"),\n",
        "                    ],\n",
        "                },\n",
        "                {\n",
        "                    \"selector\": \"caption\",\n",
        "                    \"props\": [\n",
        "                        (\"caption-side\", \"top\"),\n",
        "                        (\"text-align\", \"left\"),\n",
        "                        (\"font-weight\", \"bold\"),\n",
        "                    ],\n",
        "                },\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if caption:\n",
        "        styler = styler.set_caption(caption)\n",
        "\n",
        "    display(styler)\n",
        "\n",
        "\n",
        "NEGATIVE_RECOMMENDATIONS = {\n",
        "    \"greeting\": \"Начинайте сообщение с короткого персонального приветствия, чтобы сразу зафиксировать контакт.\",\n",
        "    \"upsell\": \"Добавляйте следующий платный шаг, релевантный контексту клиента, а не только скидку или статус.\",\n",
        "    \"empathy\": \"Явно признавайте ситуацию клиента одной фразой перед предложением решения.\",\n",
        "}\n",
        "\n",
        "RUN_ID = latest_run_id()\n",
        "print(f\"Используется последний успешный run_id: {RUN_ID}\")\n",
        "print(f\"Используется база: {DB_PATH}\")\n",
        "print(\"Проверка визуала: display.max_colwidth =\", pd.get_option(\"display.max_colwidth\"))\n",
        "assert pd.get_option(\"display.max_colwidth\") is None\n"
      ]
    },
    {
      "id": "md-002",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Что происходит в последнем запуске\n",
        "\n",
        "Ниже KPI-карточки по **latest run**: объем проверки, доля подтвержденных оценок и масштаб хороших/негативных кейсов.\n"
      ]
    },
    {
      "id": "code-003",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "run_snapshot = qdf(\n",
        "    \"\"\"\n",
        "    WITH latest_run AS (\n",
        "        SELECT run_id\n",
        "        FROM scan_runs\n",
        "        WHERE status = 'success'\n",
        "        ORDER BY started_at_utc DESC\n",
        "        LIMIT 1\n",
        "    )\n",
        "    SELECT\n",
        "        run_id,\n",
        "        model,\n",
        "        selected_conversations,\n",
        "        messages_count,\n",
        "        started_at_utc,\n",
        "        finished_at_utc,\n",
        "        json_extract(summary_json, '$.processed') AS processed,\n",
        "        json_extract(summary_json, '$.inserted') AS inserted,\n",
        "        json_extract(summary_json, '$.judged') AS judged,\n",
        "        json_extract(summary_json, '$.skipped_due_to_errors') AS skipped_due_to_errors\n",
        "    FROM scan_runs\n",
        "    WHERE run_id = (SELECT run_id FROM latest_run)\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "kpi = qdf(\n",
        "    \"\"\"\n",
        "    WITH latest_run AS (\n",
        "        SELECT run_id\n",
        "        FROM scan_runs\n",
        "        WHERE status = 'success'\n",
        "        ORDER BY started_at_utc DESC\n",
        "        LIMIT 1\n",
        "    ),\n",
        "    base AS (\n",
        "        SELECT\n",
        "            sr.message_id,\n",
        "            sr.judge_label\n",
        "        FROM scan_results sr\n",
        "        JOIN messages m ON m.message_id = sr.message_id\n",
        "        WHERE sr.run_id = (SELECT run_id FROM latest_run)\n",
        "          AND m.speaker_label = 'Sales Rep'\n",
        "    ),\n",
        "    scored AS (\n",
        "        SELECT\n",
        "            b.*,\n",
        "            AVG(CASE WHEN b.judge_label = 1 THEN 1.0 ELSE 0.0 END)\n",
        "                OVER (PARTITION BY b.message_id) AS final_score\n",
        "        FROM base b\n",
        "    )\n",
        "    SELECT\n",
        "        COUNT(*) AS total_rule_checks,\n",
        "        SUM(CASE WHEN judge_label IS NOT NULL THEN 1 ELSE 0 END) AS judged_checks,\n",
        "        SUM(CASE WHEN judge_label = 1 THEN 1 ELSE 0 END) AS judge_confirmed_checks,\n",
        "        SUM(CASE WHEN judge_label = 0 THEN 1 ELSE 0 END) AS negative_checks,\n",
        "        COUNT(DISTINCT CASE WHEN final_score >= 0.90 THEN message_id END) AS strong_messages,\n",
        "        COUNT(DISTINCT message_id) AS evaluated_messages,\n",
        "        CASE\n",
        "            WHEN SUM(CASE WHEN judge_label IS NOT NULL THEN 1 ELSE 0 END) = 0 THEN NULL\n",
        "            ELSE 1.0 * SUM(CASE WHEN judge_label = 1 THEN 1 ELSE 0 END)\n",
        "                 / SUM(CASE WHEN judge_label IS NOT NULL THEN 1 ELSE 0 END)\n",
        "        END AS judge_correctness\n",
        "    FROM scored\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "cards = pd.DataFrame(\n",
        "    [\n",
        "        {\"Показатель\": \"Run ID\", \"Значение\": str(run_snapshot.loc[0, \"run_id\"])},\n",
        "        {\"Показатель\": \"Модель\", \"Значение\": str(run_snapshot.loc[0, \"model\"])},\n",
        "        {\"Показатель\": \"Проверок по правилам\", \"Значение\": int(kpi.loc[0, \"total_rule_checks\"])},\n",
        "        {\"Показатель\": \"Проверок с вердиктом judge\", \"Значение\": int(kpi.loc[0, \"judged_checks\"])},\n",
        "        {\"Показатель\": \"Доля подтвержденных оценок\", \"Значение\": as_pct(kpi.loc[0, \"judge_correctness\"])},\n",
        "        {\"Показатель\": \"Сильных сообщений (>=0.90)\", \"Значение\": int(kpi.loc[0, \"strong_messages\"])},\n",
        "        {\"Показатель\": \"Негативных проверок\", \"Значение\": int(kpi.loc[0, \"negative_checks\"])},\n",
        "    ]\n",
        ")\n",
        "\n",
        "style_business_table(cards, caption=\"KPI latest run\")\n",
        "\n",
        "run_view = run_snapshot.rename(\n",
        "    columns={\n",
        "        \"selected_conversations\": \"Выбрано диалогов\",\n",
        "        \"messages_count\": \"Сообщений в диапазоне\",\n",
        "        \"started_at_utc\": \"Старт (UTC)\",\n",
        "        \"finished_at_utc\": \"Завершение (UTC)\",\n",
        "        \"processed\": \"Обработано кейсов\",\n",
        "        \"inserted\": \"Сохранено результатов\",\n",
        "        \"judged\": \"Проставлено judge\",\n",
        "        \"skipped_due_to_errors\": \"Пропущено из-за ошибок\",\n",
        "    }\n",
        ")\n",
        "style_business_table(run_view.drop(columns=[\"run_id\", \"model\"]), caption=\"Снимок запуска\")\n"
      ]
    },
    {
      "id": "md-004",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Сильные кейсы (почему хорошо)\n",
        "\n",
        "Контракт отбора (SQL):\n",
        "- берем только `Sales Rep`;\n",
        "- считаем `final_score` по сообщению;\n",
        "- оставляем `final_score >= 0.90` и `judge_label = 1`.\n",
        "\n",
        "Ниже показывается **полная таблица** (не `head()`) с длинными текстами без обрезки.\n"
      ]
    },
    {
      "id": "code-005",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "good_cases = qdf(\n",
        "    \"\"\"\n",
        "    WITH latest_run AS (\n",
        "        SELECT run_id\n",
        "        FROM scan_runs\n",
        "        WHERE status = 'success'\n",
        "        ORDER BY started_at_utc DESC\n",
        "        LIMIT 1\n",
        "    ),\n",
        "    base AS (\n",
        "        SELECT\n",
        "            sr.message_id,\n",
        "            m.text AS message,\n",
        "            sr.rule_key,\n",
        "            sr.eval_hit,\n",
        "            sr.judge_expected_hit,\n",
        "            sr.judge_label,\n",
        "            sr.eval_confidence,\n",
        "            sr.judge_confidence,\n",
        "            sr.eval_reason_code,\n",
        "            sr.eval_reason,\n",
        "            sr.judge_rationale,\n",
        "            sr.evidence_quote\n",
        "        FROM scan_results sr\n",
        "        JOIN messages m ON m.message_id = sr.message_id\n",
        "        WHERE sr.run_id = (SELECT run_id FROM latest_run)\n",
        "          AND m.speaker_label = 'Sales Rep'\n",
        "    ),\n",
        "    scored AS (\n",
        "        SELECT\n",
        "            b.*,\n",
        "            AVG(CASE WHEN b.judge_label = 1 THEN 1.0 ELSE 0.0 END)\n",
        "                OVER (PARTITION BY b.message_id) AS final_score,\n",
        "            SUM(CASE WHEN b.judge_label = 1 THEN 1 ELSE 0 END)\n",
        "                OVER (PARTITION BY b.message_id) AS good_rules,\n",
        "            COUNT(*) OVER (PARTITION BY b.message_id) AS total_rules\n",
        "        FROM base b\n",
        "    )\n",
        "    SELECT\n",
        "        s.message,\n",
        "        s.rule_key AS rule,\n",
        "        s.eval_hit AS evaluator_hit,\n",
        "        s.judge_expected_hit AS expected_hit_by_judge,\n",
        "        ROUND(s.eval_confidence, 3) AS eval_conf,\n",
        "        ROUND(s.judge_confidence, 3) AS judge_conf,\n",
        "        s.eval_reason_code,\n",
        "        s.eval_reason AS evaluator_why,\n",
        "        s.judge_rationale AS judge_why,\n",
        "        s.evidence_quote AS quote_from_message,\n",
        "        ROUND(s.final_score, 3) AS final_score_for_message,\n",
        "        (s.good_rules || '/' || s.total_rules) AS good_rules_for_message\n",
        "    FROM scored s\n",
        "    WHERE s.final_score >= 0.90\n",
        "      AND s.judge_label = 1\n",
        "    ORDER BY s.final_score DESC, s.judge_confidence DESC, s.message, s.rule_key\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(f\"Найдено сильных проверок: {len(good_cases)}\")\n",
        "\n",
        "good_business = good_cases.rename(\n",
        "    columns={\n",
        "        \"message\": \"Сообщение продавца\",\n",
        "        \"rule\": \"Правило (Rule)\",\n",
        "        \"evaluator_hit\": \"Решение evaluator\",\n",
        "        \"expected_hit_by_judge\": \"Ожидание judge\",\n",
        "        \"eval_conf\": \"Уверенность evaluator\",\n",
        "        \"judge_conf\": \"Уверенность judge\",\n",
        "        \"eval_reason_code\": \"Код причины evaluator\",\n",
        "        \"evaluator_why\": \"Почему evaluator так решил\",\n",
        "        \"judge_why\": \"Почему judge согласен/не согласен\",\n",
        "        \"quote_from_message\": \"Дословная цитата из сообщения\",\n",
        "        \"final_score_for_message\": \"Итоговая оценка сообщения\",\n",
        "        \"good_rules_for_message\": \"Сколько правил выполнено\",\n",
        "    }\n",
        ")\n",
        "\n",
        "if not good_business.empty:\n",
        "    good_business[\"Решение evaluator\"] = good_business[\"Решение evaluator\"].map(as_yes_no)\n",
        "    good_business[\"Ожидание judge\"] = good_business[\"Ожидание judge\"].map(as_yes_no)\n",
        "\n",
        "style_business_table(good_business, caption=\"Сильные кейсы: полная таблица latest run\")\n"
      ]
    },
    {
      "id": "md-006",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Негативные кейсы (что исправить)\n",
        "\n",
        "Источник: **только последний успешный run** (`latest_run`) и `judge_label = 0`.\n",
        "\n",
        "Ниже показываются понятные для бизнеса поля и отдельная колонка `Рекомендация для бизнеса`.\n"
      ]
    },
    {
      "id": "code-007",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "negative_cases = qdf(\n",
        "    \"\"\"\n",
        "    WITH latest_run AS (\n",
        "        SELECT run_id\n",
        "        FROM scan_runs\n",
        "        WHERE status = 'success'\n",
        "        ORDER BY started_at_utc DESC\n",
        "        LIMIT 1\n",
        "    )\n",
        "    SELECT\n",
        "        sr.conversation_id,\n",
        "        sr.message_id,\n",
        "        m.text AS message,\n",
        "        sr.rule_key,\n",
        "        sr.eval_hit,\n",
        "        sr.judge_expected_hit,\n",
        "        ROUND(sr.eval_confidence, 3) AS eval_conf,\n",
        "        ROUND(sr.judge_confidence, 3) AS judge_conf,\n",
        "        sr.eval_reason_code,\n",
        "        sr.eval_reason,\n",
        "        sr.judge_rationale,\n",
        "        sr.evidence_quote\n",
        "    FROM scan_results sr\n",
        "    JOIN messages m ON m.message_id = sr.message_id\n",
        "    WHERE sr.run_id = (SELECT run_id FROM latest_run)\n",
        "      AND m.speaker_label = 'Sales Rep'\n",
        "      AND sr.judge_label = 0\n",
        "    ORDER BY COALESCE(sr.judge_confidence, 0) DESC, sr.message_id, sr.rule_key\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(f\"Негативных проверок в latest run: {len(negative_cases)}\")\n",
        "\n",
        "if negative_cases.empty:\n",
        "    print(\"Негативных кейсов не найдено в последнем успешном запуске.\")\n",
        "else:\n",
        "    negative_business = negative_cases.rename(\n",
        "        columns={\n",
        "            \"message\": \"Сообщение продавца\",\n",
        "            \"rule_key\": \"Правило (Rule)\",\n",
        "            \"eval_hit\": \"Решение evaluator\",\n",
        "            \"judge_expected_hit\": \"Ожидание judge\",\n",
        "            \"eval_conf\": \"Уверенность evaluator\",\n",
        "            \"judge_conf\": \"Уверенность judge\",\n",
        "            \"eval_reason_code\": \"Код причины evaluator\",\n",
        "            \"eval_reason\": \"Почему evaluator так решил\",\n",
        "            \"judge_rationale\": \"Почему judge согласен/не согласен\",\n",
        "            \"evidence_quote\": \"Дословная цитата из сообщения\",\n",
        "        }\n",
        "    ).copy()\n",
        "\n",
        "    negative_business[\"Решение evaluator\"] = negative_business[\"Решение evaluator\"].map(as_yes_no)\n",
        "    negative_business[\"Ожидание judge\"] = negative_business[\"Ожидание judge\"].map(as_yes_no)\n",
        "    negative_business[\"Рекомендация для бизнеса\"] = negative_business[\"Правило (Rule)\"].map(NEGATIVE_RECOMMENDATIONS).fillna(\n",
        "        \"Разобрать кейс вручную и обновить playbook команды продаж.\"\n",
        "    )\n",
        "\n",
        "    negative_business = negative_business[\n",
        "        [\n",
        "            \"Сообщение продавца\",\n",
        "            \"Правило (Rule)\",\n",
        "            \"Решение evaluator\",\n",
        "            \"Ожидание judge\",\n",
        "            \"Уверенность evaluator\",\n",
        "            \"Уверенность judge\",\n",
        "            \"Код причины evaluator\",\n",
        "            \"Почему evaluator так решил\",\n",
        "            \"Почему judge согласен/не согласен\",\n",
        "            \"Дословная цитата из сообщения\",\n",
        "            \"Рекомендация для бизнеса\",\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    style_business_table(negative_business, caption=\"Негативные кейсы latest run: полная таблица\")\n"
      ]
    },
    {
      "id": "md-008",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Глоссарий бизнес-полей (RU + EN)\n",
        "\n",
        "Этот блок нужен, чтобы C-level и команда аналитики читали метрики одинаково.\n"
      ]
    },
    {
      "id": "code-009",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "glossary = pd.DataFrame(\n",
        "    [\n",
        "        {\"Поле\": \"judge_correctness\", \"RU\": \"Доля оценок evaluator, подтвержденных judge\", \"EN\": \"Evaluator correctness rate\"},\n",
        "        {\"Поле\": \"judge_label\", \"RU\": \"Вердикт judge: evaluator корректен (1) или нет (0)\", \"EN\": \"Judge verdict\"},\n",
        "        {\"Поле\": \"judge_expected_hit\", \"RU\": \"Какой hit judge считает правильным\", \"EN\": \"Judge expected hit\"},\n",
        "        {\"Поле\": \"eval_hit\", \"RU\": \"Решение evaluator по правилу\", \"EN\": \"Evaluator hit decision\"},\n",
        "        {\"Поле\": \"eval_reason\", \"RU\": \"Объяснение evaluator\", \"EN\": \"Evaluator rationale\"},\n",
        "        {\"Поле\": \"judge_rationale\", \"RU\": \"Объяснение judge\", \"EN\": \"Judge rationale\"},\n",
        "        {\"Поле\": \"evidence_quote\", \"RU\": \"Дословная цитата из сообщения\", \"EN\": \"Evidence quote\"},\n",
        "        {\"Поле\": \"final_score_for_message\", \"RU\": \"Итоговый score сообщения по подтвержденным правилам\", \"EN\": \"Final message score\"},\n",
        "        {\"Поле\": \"good_rules_for_message\", \"RU\": \"Количество подтвержденных правил из общего числа\", \"EN\": \"Passed rules ratio\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "style_business_table(glossary, caption=\"Глоссарий метрик и полей\")\n"
      ]
    },
    {
      "id": "md-010",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Technical Appendix (для инженеров и аудита)\n",
        "\n",
        "Здесь намеренно оставлены ID и технические поля для дебага.\n"
      ]
    },
    {
      "id": "code-011",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "appendix_neg = qdf(\n",
        "    \"\"\"\n",
        "    WITH latest_run AS (\n",
        "        SELECT run_id\n",
        "        FROM scan_runs\n",
        "        WHERE status = 'success'\n",
        "        ORDER BY started_at_utc DESC\n",
        "        LIMIT 1\n",
        "    )\n",
        "    SELECT\n",
        "        sr.conversation_id,\n",
        "        sr.message_id,\n",
        "        sr.rule_key,\n",
        "        sr.eval_hit,\n",
        "        sr.judge_expected_hit,\n",
        "        sr.judge_label,\n",
        "        sr.eval_confidence,\n",
        "        sr.judge_confidence,\n",
        "        sr.eval_reason_code,\n",
        "        sr.eval_reason,\n",
        "        sr.judge_rationale,\n",
        "        sr.evidence_quote,\n",
        "        sr.evidence_message_id,\n",
        "        sr.evidence_span_start,\n",
        "        sr.evidence_span_end\n",
        "    FROM scan_results sr\n",
        "    JOIN messages m ON m.message_id = sr.message_id\n",
        "    WHERE sr.run_id = ?\n",
        "      AND m.speaker_label = 'Sales Rep'\n",
        "      AND sr.judge_label = 0\n",
        "    ORDER BY sr.message_id, sr.rule_key\n",
        "    \"\"\",\n",
        "    (RUN_ID,),\n",
        ")\n",
        "\n",
        "llm_trace = qdf(\n",
        "    \"\"\"\n",
        "    SELECT phase,\n",
        "           COUNT(*) AS calls,\n",
        "           SUM(CASE WHEN error_message <> '' THEN 1 ELSE 0 END) AS errors,\n",
        "           ROUND(AVG(latency_ms), 1) AS avg_latency_ms,\n",
        "           MAX(latency_ms) AS max_latency_ms\n",
        "    FROM llm_calls\n",
        "    WHERE run_id = ?\n",
        "    GROUP BY phase\n",
        "    ORDER BY phase\n",
        "    \"\"\",\n",
        "    (RUN_ID,),\n",
        ")\n",
        "\n",
        "print(\"Appendix: негативные кейсы с ID и evidence span\")\n",
        "if appendix_neg.empty:\n",
        "    print(\"В latest run нет негативных кейсов для технического разбора.\")\n",
        "else:\n",
        "    display(appendix_neg)\n",
        "\n",
        "print(\"\\nAppendix: сводка по LLM вызовам\")\n",
        "if llm_trace.empty:\n",
        "    print(\"Для latest run не найдено записей в llm_calls.\")\n",
        "else:\n",
        "    display(llm_trace)\n"
      ]
    },
    {
      "id": "code-012",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "conn.close()\n"
      ]
    }
  ]
}
